{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e71b7",
   "metadata": {},
   "source": [
    "## Business Logic Layer\n",
    "\n",
    "This module provides the service layer for processing chat messages and handling business logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Responder\n",
       "\n",
       ">      Responder (*args, **kwargs)\n",
       "\n",
       "*Protocol for chat responders (LLMs, APIs, etc.).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Responder\n",
       "\n",
       ">      Responder (*args, **kwargs)\n",
       "\n",
       "*Protocol for chat responders (LLMs, APIs, etc.).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Responder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ErrorHandler\n",
       "\n",
       ">      ErrorHandler (*args, **kwargs)\n",
       "\n",
       "*Protocol for handling errors during message processing.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ErrorHandler\n",
       "\n",
       ">      ErrorHandler (*args, **kwargs)\n",
       "\n",
       "*Protocol for handling errors during message processing.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ErrorHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DefaultErrorHandler\n",
       "\n",
       ">      DefaultErrorHandler (include_details:bool=True)\n",
       "\n",
       "*Default error handler implementation.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DefaultErrorHandler\n",
       "\n",
       ">      DefaultErrorHandler (include_details:bool=True)\n",
       "\n",
       "*Default error handler implementation.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DefaultErrorHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ChatService\n",
       "\n",
       ">      ChatService (responder:Union[__main__.Responder,Callable],\n",
       ">                   error_handler:Optional[__main__.ErrorHandler]=None, context_\n",
       ">                   provider:Optional[Callable[[pylogue.session.ChatSession],Any\n",
       ">                   ]]=None)\n",
       "\n",
       "*Service for processing chat messages with responders.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ChatService\n",
       "\n",
       ">      ChatService (responder:Union[__main__.Responder,Callable],\n",
       ">                   error_handler:Optional[__main__.ErrorHandler]=None, context_\n",
       ">                   provider:Optional[Callable[[pylogue.session.ChatSession],Any\n",
       ">                   ]]=None)\n",
       "\n",
       "*Service for processing chat messages with responders.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ChatService)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5e17",
   "metadata": {},
   "source": [
    "## Example Responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### echo_responder\n",
       "\n",
       ">      echo_responder (message:str, context:Optional[Any]=None)\n",
       "\n",
       "*Simple echo responder for testing.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### echo_responder\n",
       "\n",
       ">      echo_responder (message:str, context:Optional[Any]=None)\n",
       "\n",
       "*Simple echo responder for testing.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(echo_responder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ContextAwareResponder\n",
       "\n",
       ">      ContextAwareResponder (max_history:int=5)\n",
       "\n",
       "*Example responder that uses conversation history.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ContextAwareResponder\n",
       "\n",
       ">      ContextAwareResponder (max_history:int=5)\n",
       "\n",
       "*Example responder that uses conversation history.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ContextAwareResponder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219d698",
   "metadata": {},
   "source": [
    "## Test the Service Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9704f62",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [Echo] You said: Hello, world!\n"
     ]
    }
   ],
   "source": [
    "# Test basic ChatService\n",
    "from pylogue.session import ChatSession\n",
    "\n",
    "service = ChatService(responder=echo_responder)\n",
    "response = await service.process_message(\"Hello, world!\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89db3416",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session messages: [{'role': 'User', 'content': 'First message', 'id': 'eb9c84e7-f898-4514-8bf9-aac2c4ece363'}, {'role': 'Assistant', 'content': '[Echo] You said: First message', 'id': '52451b28-a288-4cb5-8ec7-c139daf736f7'}]\n"
     ]
    }
   ],
   "source": [
    "# Test with session\n",
    "session = ChatSession(\"test-session\")\n",
    "service = ChatService(responder=echo_responder)\n",
    "\n",
    "assistant_msg = await service.process_session_message(session, \"First message\")\n",
    "print(f\"Session messages: {session.get_message_dicts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9b43cf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final messages: [{'role': 'User', 'content': 'First', 'id': 'a9b83b5a-9c29-46d3-a3c3-179ca1d77b7f'}, {'role': 'Assistant', 'content': \"I see we've exchanged 1 messages. You just said: First\", 'id': '555f171f-fbfa-4b2c-b6e3-0e754093c006'}, {'role': 'User', 'content': 'Second', 'id': 'b1bb1984-8154-4cfb-8372-67c73315467d'}, {'role': 'Assistant', 'content': \"I see we've exchanged 3 messages. You just said: Second\", 'id': '471f8465-d3b2-46f5-8fb1-e14cef42a030'}, {'role': 'User', 'content': 'Third', 'id': '9cd1d761-fa34-4eca-aadf-acffe180a238'}, {'role': 'Assistant', 'content': \"I see we've exchanged 5 messages. You just said: Third\", 'id': 'e47b7fba-92ab-4fbf-829f-9e86d8afb7a5'}]\n"
     ]
    }
   ],
   "source": [
    "# Test context-aware responder\n",
    "def context_provider(session: ChatSession):\n",
    "    \"\"\"Provide message history as context.\"\"\"\n",
    "    return session.get_messages()\n",
    "\n",
    "\n",
    "session = ChatSession(\"context-test\")\n",
    "responder = ContextAwareResponder()\n",
    "service = ChatService(responder=responder, context_provider=context_provider)\n",
    "\n",
    "await service.process_session_message(session, \"First\")\n",
    "await service.process_session_message(session, \"Second\")\n",
    "await service.process_session_message(session, \"Third\")\n",
    "\n",
    "print(f\"Final messages: {session.get_message_dicts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e420e415",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response: Error processing message: ValueError: Something went wrong!\n"
     ]
    }
   ],
   "source": [
    "# Test error handling\n",
    "def failing_responder(message: str, context=None):\n",
    "    raise ValueError(\"Something went wrong!\")\n",
    "\n",
    "\n",
    "service = ChatService(responder=failing_responder)\n",
    "response = await service.process_message(\"This will fail\")\n",
    "print(f\"Error response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672863f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylogue (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
