{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd53d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efb9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import Protocol, Callable, Awaitable, Union, Optional, Any\n",
    "import inspect\n",
    "import asyncio\n",
    "from pylogue.session import Message, ChatSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e71b7",
   "metadata": {},
   "source": [
    "## Business Logic Layer\n",
    "\n",
    "This module provides the service layer for processing chat messages and handling business logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11bfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Responder(Protocol):\n",
    "    \"\"\"Protocol for chat responders (LLMs, APIs, etc.).\"\"\"\n",
    "\n",
    "    async def __call__(self, message: str, context: Optional[Any] = None) -> str:\n",
    "        \"\"\"Process a message and return a response.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc058e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ErrorHandler(Protocol):\n",
    "    \"\"\"Protocol for handling errors during message processing.\"\"\"\n",
    "\n",
    "    def __call__(self, error: Exception, message: str) -> str:\n",
    "        \"\"\"Handle an error and return a user-friendly message.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edb48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class DefaultErrorHandler:\n",
    "    \"\"\"Default error handler implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, include_details: bool = True):\n",
    "        self.include_details = include_details\n",
    "\n",
    "    def __call__(self, error: Exception, message: str) -> str:\n",
    "        \"\"\"Handle an error and return a user-friendly message.\"\"\"\n",
    "        if self.include_details:\n",
    "            return f\"Error processing message: {type(error).__name__}: {str(error)}\"\n",
    "        return \"Sorry, I encountered an error processing your message.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8433f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ChatService:\n",
    "    \"\"\"Service for processing chat messages with responders.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        responder: Union[Responder, Callable],\n",
    "        error_handler: Optional[ErrorHandler] = None,\n",
    "        context_provider: Optional[Callable[[ChatSession], Any]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize ChatService.\n",
    "\n",
    "        Args:\n",
    "            responder: Function/callable that processes messages and returns responses\n",
    "            error_handler: Handler for processing errors\n",
    "            context_provider: Optional function to extract context from session\n",
    "        \"\"\"\n",
    "        self.responder = responder\n",
    "        self.error_handler = error_handler or DefaultErrorHandler()\n",
    "        self.context_provider = context_provider\n",
    "\n",
    "    async def process_message(\n",
    "        self, user_message: str, session: Optional[ChatSession] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Process a user message and return the assistant's response.\n",
    "\n",
    "        Args:\n",
    "            user_message: The user's input message\n",
    "            session: Optional chat session for context\n",
    "\n",
    "        Returns:\n",
    "            The assistant's response string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract context if provider exists\n",
    "            context = None\n",
    "            if self.context_provider and session:\n",
    "                context = self.context_provider(session)\n",
    "\n",
    "            # Call responder\n",
    "            if inspect.iscoroutinefunction(self.responder):\n",
    "                result = await self.responder(user_message, context)\n",
    "            else:\n",
    "                result = self.responder(user_message, context)\n",
    "                if inspect.isawaitable(result):\n",
    "                    result = await result\n",
    "\n",
    "            return str(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            return self.error_handler(e, user_message)\n",
    "\n",
    "    async def process_session_message(\n",
    "        self, session: ChatSession, user_message: str, add_to_session: bool = True\n",
    "    ) -> Message:\n",
    "        \"\"\"\n",
    "        Process a message within a session context.\n",
    "\n",
    "        Args:\n",
    "            session: The chat session\n",
    "            user_message: The user's input\n",
    "            add_to_session: Whether to add user message to session\n",
    "\n",
    "        Returns:\n",
    "            The assistant's response as a Message object\n",
    "        \"\"\"\n",
    "        # Add user message if requested\n",
    "        if add_to_session:\n",
    "            session.add_message(\"User\", user_message)\n",
    "\n",
    "        # Process and get response\n",
    "        response = await self.process_message(user_message, session)\n",
    "\n",
    "        # Create and add assistant message\n",
    "        assistant_msg = session.add_message(\"Assistant\", response)\n",
    "        return assistant_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5e17",
   "metadata": {},
   "source": [
    "## Example Responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efd1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def echo_responder(message: str, context: Optional[Any] = None) -> str:\n",
    "    \"\"\"Simple echo responder for testing.\"\"\"\n",
    "    await asyncio.sleep(0.2)  # Simulate latency\n",
    "    return f\"[Echo] You said: {message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1b368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ContextAwareResponder:\n",
    "    \"\"\"Example responder that uses conversation history.\"\"\"\n",
    "\n",
    "    def __init__(self, max_history: int = 5):\n",
    "        self.max_history = max_history\n",
    "\n",
    "    async def __call__(self, message: str, context: Optional[Any] = None) -> str:\n",
    "        \"\"\"Generate response with context awareness.\"\"\"\n",
    "        await asyncio.sleep(0.1)\n",
    "\n",
    "        if context and isinstance(context, list):\n",
    "            history_count = len(context)\n",
    "            return f\"I see we've exchanged {history_count} messages. You just said: {message}\"\n",
    "\n",
    "        return f\"Hello! You said: {message}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219d698",
   "metadata": {},
   "source": [
    "## Test the Service Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9704f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [Echo] You said: Hello, world!\n"
     ]
    }
   ],
   "source": [
    "# Test basic ChatService\n",
    "from pylogue.session import ChatSession\n",
    "\n",
    "service = ChatService(responder=echo_responder)\n",
    "response = await service.process_message(\"Hello, world!\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89db3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session messages: [{'role': 'User', 'content': 'First message', 'id': 'eb9c84e7-f898-4514-8bf9-aac2c4ece363'}, {'role': 'Assistant', 'content': '[Echo] You said: First message', 'id': '52451b28-a288-4cb5-8ec7-c139daf736f7'}]\n"
     ]
    }
   ],
   "source": [
    "# Test with session\n",
    "session = ChatSession(\"test-session\")\n",
    "service = ChatService(responder=echo_responder)\n",
    "\n",
    "assistant_msg = await service.process_session_message(session, \"First message\")\n",
    "print(f\"Session messages: {session.get_message_dicts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9b43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final messages: [{'role': 'User', 'content': 'First', 'id': 'a9b83b5a-9c29-46d3-a3c3-179ca1d77b7f'}, {'role': 'Assistant', 'content': \"I see we've exchanged 1 messages. You just said: First\", 'id': '555f171f-fbfa-4b2c-b6e3-0e754093c006'}, {'role': 'User', 'content': 'Second', 'id': 'b1bb1984-8154-4cfb-8372-67c73315467d'}, {'role': 'Assistant', 'content': \"I see we've exchanged 3 messages. You just said: Second\", 'id': '471f8465-d3b2-46f5-8fb1-e14cef42a030'}, {'role': 'User', 'content': 'Third', 'id': '9cd1d761-fa34-4eca-aadf-acffe180a238'}, {'role': 'Assistant', 'content': \"I see we've exchanged 5 messages. You just said: Third\", 'id': 'e47b7fba-92ab-4fbf-829f-9e86d8afb7a5'}]\n"
     ]
    }
   ],
   "source": [
    "# Test context-aware responder\n",
    "def context_provider(session: ChatSession):\n",
    "    \"\"\"Provide message history as context.\"\"\"\n",
    "    return session.get_messages()\n",
    "\n",
    "\n",
    "session = ChatSession(\"context-test\")\n",
    "responder = ContextAwareResponder()\n",
    "service = ChatService(responder=responder, context_provider=context_provider)\n",
    "\n",
    "await service.process_session_message(session, \"First\")\n",
    "await service.process_session_message(session, \"Second\")\n",
    "await service.process_session_message(session, \"Third\")\n",
    "\n",
    "print(f\"Final messages: {session.get_message_dicts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e420e415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response: Error processing message: ValueError: Something went wrong!\n"
     ]
    }
   ],
   "source": [
    "# Test error handling\n",
    "def failing_responder(message: str, context=None):\n",
    "    raise ValueError(\"Something went wrong!\")\n",
    "\n",
    "\n",
    "service = ChatService(responder=failing_responder)\n",
    "response = await service.process_message(\"This will fail\")\n",
    "print(f\"Error response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672863f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylogue (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
